using System;
using System.IO;
using System.Collections;
using UnityEngine;
using NativeWebSocket;

public class AudioManager : MonoBehaviour
{
    AudioClip myclip;
    AudioSource audioSource;
    [SerializeField] string micName;
    int samplingFrequency = 44100;
    int maxTime = 15;

    public float recordStartTime;
    private AudioClip recordedClip;

    [Header("çµæœè¡¨ç¤ºç”¨ï¼ˆã‚µãƒ¼ãƒãƒ¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼‰")]
    public TextMesh resultText;

    [Header("ãƒ­ã‚°è¡¨ç¤ºç”¨ï¼ˆå‹•ä½œçŠ¶æ³ãªã©ï¼‰")]
    public TextMesh logText;

    WebSocket websocket;

    async void Start()
    {
        if (Microphone.devices.Length == 0)
        {
            LogMessage("ãƒã‚¤ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚");
            return;
        }

        micName = Microphone.devices[0];
        LogMessage("ä½¿ç”¨ãƒã‚¤ã‚¯ï¼š" + micName);

        audioSource = gameObject.AddComponent<AudioSource>();

        // WebSocket åˆæœŸåŒ–
        websocket = new WebSocket("ws://172.21.1.123:8000/ws");

        websocket.OnOpen += () =>
        {
            LogMessage("âœ“ WebSocket æ¥ç¶šæˆåŠŸï¼");
        };

        websocket.OnError += (e) =>
        {
            LogMessage("âœ— WebSocket ã‚¨ãƒ©ãƒ¼: " + e);
        };

        websocket.OnClose += (e) =>
        {
            LogMessage("WebSocket æ¥ç¶šé–‰ã˜ã¾ã—ãŸã€‚Code: " + e);
        };

        websocket.OnMessage += (bytes) =>
        {
            string message = System.Text.Encoding.UTF8.GetString(bytes);
            LogMessage("å—ä¿¡: " + message.Substring(0, Math.Min(100, message.Length)) + "...");
            HandleMessage(message);
        };

        await websocket.Connect();
    }

    private void Update()
    {
#if !UNITY_WEBGL || UNITY_EDITOR
        websocket?.DispatchMessageQueue();
#endif
    }

    // éŒ²éŸ³é–‹å§‹
    public void StartButton()
    {
        LogMessage("ğŸ¤ éŒ²éŸ³é–‹å§‹ï¼");
        myclip = Microphone.Start(micName, false, maxTime, samplingFrequency);
        recordStartTime = Time.time;
    }

    // éŒ²éŸ³çµ‚äº†
    public void EndButton()
    {
        if (!Microphone.IsRecording(micName))
        {
            LogMessage("âš ï¸ éŒ²éŸ³ä¸­ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚");
            return;
        }

        Microphone.End(micName);
        LogMessage("â¹ï¸ éŒ²éŸ³åœæ­¢");

        float recordDuration = Time.time - recordStartTime;
        if (recordDuration > maxTime) recordDuration = maxTime;

        int sampleLength = (int)(recordDuration * samplingFrequency) * myclip.channels;
        float[] samples = new float[sampleLength];
        myclip.GetData(samples, 0);

        recordedClip = AudioClip.Create("RecordedClip", sampleLength / myclip.channels, myclip.channels, samplingFrequency, false);
        recordedClip.SetData(samples, 0);

        myclip = recordedClip;
        LogMessage("âœ“ éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ä½œæˆå®Œäº† (" + recordDuration.ToString("F2") + "ç§’)");
    }

    // éŸ³å£°å†ç”Ÿ
    public void PlayButton()
    {
        if (myclip == null)
        {
            LogMessage("âš ï¸ å†ç”Ÿãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚");
            return;
        }

        audioSource.clip = myclip;
        audioSource.Play();
        LogMessage("â–¶ï¸ éŸ³å£°ã‚’å†ç”Ÿä¸­...");
    }

    // WAVä¿å­˜
    public void SaveWav()
    {
        if (myclip == null)
        {
            LogMessage("âš ï¸ éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¿å­˜ã§ãã¾ã›ã‚“ã€‚");
            return;
        }

        string path = Path.Combine(Application.persistentDataPath, "myRecording.wav");
        WavUtility.FromAudioClip(myclip, path, true);
        LogMessage("ğŸ’¾ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜: " + path);
    }

    // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ WebSocket ã§é€ä¿¡ï¼ˆæ–‡å­—èµ·ã“ã—ç”¨ï¼‰
    public async void SendAudioViaWebSocket()
    {
        if (myclip == null)
        {
            LogMessage("âš ï¸ é€ä¿¡ã™ã‚‹éŸ³å£°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚");
            return;
        }

        // WebSocket æ¥ç¶šãƒã‚§ãƒƒã‚¯
        if (websocket == null || websocket.State != WebSocketState.Open)
        {
            LogMessage("âœ— WebSocket ãŒæ¥ç¶šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚State: " + (websocket?.State.ToString() ?? "null"));
            return;
        }

        try
        {
            LogMessage("ğŸ”„ éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›ä¸­...");

            // AudioClip ã‚’ WAV ãƒã‚¤ãƒˆé…åˆ—ã«å¤‰æ›
            byte[] wavData = ConvertAudioClipToWav(myclip);
            LogMessage("âœ“ WAVå¤‰æ›å®Œäº†: " + wavData.Length + " bytes");

            // Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            string base64Audio = Convert.ToBase64String(wavData);
            LogMessage("âœ“ Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å®Œäº†: " + base64Audio.Length + " chars");

            // ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ãªã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨
            AudioPayload payload = new AudioPayload
            {
                type = "audio",
                data = base64Audio
            };

            // JSONæ–‡å­—åˆ—ã«å¤‰æ›
            string json = JsonUtility.ToJson(payload);
            LogMessage("ğŸ“¤ é€ä¿¡ä¸­... (" + json.Length + " chars)");

            // é€ä¿¡
            await websocket.SendText(json);
            LogMessage("âœ“ éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡ã—ã¾ã—ãŸ");
        }
        catch (Exception e)
        {
            LogMessage("âœ— é€ä¿¡ã‚¨ãƒ©ãƒ¼: " + e.Message + "\n" + e.StackTrace);
        }
    }

    // ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†
    private void HandleMessage(string json)
    {
        try
        {
            // ã¾ãš type ã ã‘å–å¾—
            ServerResponse response = JsonUtility.FromJson<ServerResponse>(json);

            if (response == null || string.IsNullOrEmpty(response.type))
            {
                LogMessage("âš ï¸ ä¸æ˜ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼");
                return;
            }

            switch (response.type)
            {
                case "connection":
                    LogMessage("ğŸ”— æ¥ç¶šç¢ºèª: " + response.message);
                    break;

                case "processing":
                    LogMessage("â³ å‡¦ç†ä¸­: " + response.message);
                    if (resultText != null) resultText.text = "å‡¦ç†ä¸­...";
                    break;

                case "transcription":
                    LogMessage("ğŸ“ æ–‡å­—èµ·ã“ã—çµæœ: " + response.text);
                    if (resultText != null) resultText.text = "èªè­˜: " + response.text;
                    break;

                case "response":
                    LogMessage("ğŸ’¬ å¿œç­”: " + response.response);
                    if (resultText != null)
                    {
                        string display = "ã€å¿œç­”ã€‘\n" + response.response;
                        if (!string.IsNullOrEmpty(response.transcribed))
                        {
                            display = "ã€èªè­˜ã€‘" + response.transcribed + "\n\n" + display;
                        }
                        resultText.text = display;
                    }
                    break;

                case "error":
                    LogMessage("âœ— ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: " + response.message);
                    if (resultText != null) resultText.text = "ã‚¨ãƒ©ãƒ¼: " + response.message;
                    break;

                case "pong":
                    LogMessage("ğŸ“ Pongå—ä¿¡");
                    break;

                default:
                    LogMessage("ğŸ“¨ ãã®ä»–ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: " + response.type);
                    break;
            }
        }
        catch (Exception e)
        {
            LogMessage("âœ— JSONè§£æã‚¨ãƒ©ãƒ¼: " + e.Message);
            LogMessage("å—ä¿¡ãƒ‡ãƒ¼ã‚¿: " + json.Substring(0, Math.Min(200, json.Length)));
        }
    }

    // Pingé€ä¿¡ï¼ˆæ¥ç¶šç¢ºèªç”¨ï¼‰
    public async void SendPing()
    {
        if (websocket == null || websocket.State != WebSocketState.Open)
        {
            LogMessage("âœ— WebSocketæœªæ¥ç¶š");
            return;
        }

        try
        {
            PingPayload payload = new PingPayload { type = "ping" };
            string json = JsonUtility.ToJson(payload);
            await websocket.SendText(json);
            LogMessage("ğŸ“ Pingé€ä¿¡");
        }
        catch (Exception e)
        {
            LogMessage("âœ— Pingé€ä¿¡ã‚¨ãƒ©ãƒ¼: " + e.Message);
        }
    }

    // AudioClip â†’ WAVãƒã‚¤ãƒˆé…åˆ—
    private byte[] ConvertAudioClipToWav(AudioClip clip)
    {
        float[] samples = new float[clip.samples * clip.channels];
        clip.GetData(samples, 0);

        short[] intData = new short[samples.Length];
        byte[] bytesData = new byte[samples.Length * 2];

        int rescaleFactor = 32767;
        for (int i = 0; i < samples.Length; i++)
        {
            intData[i] = (short)(samples[i] * rescaleFactor);
            BitConverter.GetBytes(intData[i]).CopyTo(bytesData, i * 2);
        }

        // WAVå…¨ä½“ã‚µã‚¤ã‚º = ãƒ˜ãƒƒãƒ€ãƒ¼(44) + éŸ³å£°ãƒ‡ãƒ¼ã‚¿
        byte[] wav = new byte[44 + bytesData.Length];

        // WAVãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆ44ãƒã‚¤ãƒˆï¼‰
        int byteRate = clip.frequency * clip.channels * 2;
        short blockAlign = (short)(clip.channels * 2);

        // "RIFF" ãƒãƒ£ãƒ³ã‚¯
        wav[0] = 0x52; wav[1] = 0x49; wav[2] = 0x46; wav[3] = 0x46; // "RIFF"
        BitConverter.GetBytes(36 + bytesData.Length).CopyTo(wav, 4); // ChunkSize
        wav[8] = 0x57; wav[9] = 0x41; wav[10] = 0x56; wav[11] = 0x45; // "WAVE"

        // "fmt " ãƒãƒ£ãƒ³ã‚¯
        wav[12] = 0x66; wav[13] = 0x6D; wav[14] = 0x74; wav[15] = 0x20; // "fmt "
        BitConverter.GetBytes(16).CopyTo(wav, 16);  // Subchunk1Size (16 for PCM)
        BitConverter.GetBytes((short)1).CopyTo(wav, 20); // AudioFormat (1 = PCM)
        BitConverter.GetBytes((short)clip.channels).CopyTo(wav, 22); // NumChannels
        BitConverter.GetBytes(clip.frequency).CopyTo(wav, 24); // SampleRate
        BitConverter.GetBytes(byteRate).CopyTo(wav, 28); // ByteRate
        BitConverter.GetBytes(blockAlign).CopyTo(wav, 32); // BlockAlign
        BitConverter.GetBytes((short)16).CopyTo(wav, 34); // BitsPerSample

        // "data" ãƒãƒ£ãƒ³ã‚¯
        wav[36] = 0x64; wav[37] = 0x61; wav[38] = 0x74; wav[39] = 0x61; // "data"
        BitConverter.GetBytes(bytesData.Length).CopyTo(wav, 40); // Subchunk2Size

        // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼
        Buffer.BlockCopy(bytesData, 0, wav, 44, bytesData.Length);

        return wav;
    }

    // ãƒ­ã‚°è¡¨ç¤º
    void LogMessage(string message)
    {
        Debug.Log("[AudioManager] " + message);

        if (logText != null)
        {
            string timestamp = DateTime.Now.ToString("HH:mm:ss");
            logText.text = $"[{timestamp}] {message}\n" + logText.text;
            
            string[] lines = logText.text.Split('\n');
            if (lines.Length > 15)
            {
                logText.text = string.Join("\n", lines, 0, 15);
            }
        }
    }

    private async void OnApplicationQuit()
    {
        if (websocket != null && websocket.State == WebSocketState.Open)
        {
            LogMessage("WebSocketæ¥ç¶šã‚’é–‰ã˜ã¦ã„ã¾ã™...");
            await websocket.Close();
        }
    }

    private void OnDestroy()
    {
        if (websocket != null)
        {
            websocket.CancelConnection();
        }
    }
}

// ========== ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ãªã‚¯ãƒ©ã‚¹å®šç¾© ==========

[Serializable]
public class AudioPayload
{
    public string type;
    public string data;
}

[Serializable]
public class PingPayload
{
    public string type;
}

[Serializable]
public class ServerResponse
{
    public string type;           // "connection", "processing", "transcription", "response", "error"
    public string status;         // "connected", "success", "error"
    public string message;        // ä¸€èˆ¬çš„ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    public string text;           // transcriptionç”¨
    public string transcribed;    // responseç”¨ã®æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ
    public string response;       // responseç”¨ã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
    public string timestamp;      // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    public string server_time;    // ã‚µãƒ¼ãƒãƒ¼æ™‚åˆ»
    
    // classification ã¯è¤‡é›‘ãªã®ã§ã“ã“ã§ã¯çœç•¥
    // å¿…è¦ãªã‚‰ ClassificationData ã‚¯ãƒ©ã‚¹ã‚’ä½œæˆ
}

[Serializable]
public class ClassificationData
{
    public string text;
    public string category;
    public string @event;  // C#ã®äºˆç´„èªãªã®ã§ @ ã‚’ã¤ã‘ã‚‹
    public string date;
    public string time;
}